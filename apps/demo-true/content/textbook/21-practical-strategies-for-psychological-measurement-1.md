---
assignments:
- summary
chunks:
- title: Learning Objectives
  slug: Learning-Objectives-462pt
  type: plain
- title: Conceptually Defining the Construct
  slug: Conceptually-Defining-the-Construct-1681t
  type: regular
- title: Operationally Defining the Construct
  slug: Operationally-Defining-the-Construct-1682t
  type: regular
  headings:
  - level: 3
    slug: using-an-existing-measure
    title: Using an Existing Measure
- title: Operationally Defining the Construct 2
  slug: Operationally-Defining-the-Construct-2-1683t
  type: regular
  headings:
  - level: 3
    slug: creating-your-own-measure
    title: Creating Your Own Measure 
- title: Implementing the Measure
  slug: Implementing-the-Measure-1684t
  type: regular
- title: Evaluating the Measure
  slug: Evaluating-the-Measure-1680t
  type: regular
- title: References
  slug: References-463pt
  type: plain
cri:
- question: Why is having a clear and complete conceptual definition of a construct important for good measurement?
  answer: It allows you to make sound decisions about exactly how to measure the construct.
  slug: Conceptually-Defining-the-Construct-1681t
- question: Why is it usually a good idea to use an existing measure in research?
  answer: Using an existing measure can save time, has evidence of validity, and allows for easier comparison with previous research results.
  slug: Operationally-Defining-the-Construct-1682t
- question: What are some considerations to keep in mind when creating a new measure in psychology?
  answer: When creating a new measure, strive for simplicity, include clear instructions, provide practice items, keep it brief yet include multiple items, and test it on several people for feedback.
  slug: Operationally-Defining-the-Construct-2-1683t
- question: How can you minimize participant reactivity in a research study?
  answer: You can make the procedure clear and brief, guarantee anonymity, seat participants far apart in groups, use the same writing implement, not reveal your hypothesis, and standardize interactions between researchers and participants.
  slug: Implementing-the-Measure-1684t
- question: How should researchers proceed if their newly collected data cast doubt on the reliability or validity of their measure?
  answer: Researchers should investigate potential issues with the measure, administration, conceptual definition, or experimental manipulation to determine the cause of the doubt.
  slug: Evaluating-the-Measure-1680t
next_slug: null
order: 21
parent:
  title: 4. Psychological Measurement
  slug: 4-psychological-measurement
quiz: null
slug: 21-practical-strategies-for-psychological-measurement-1
title: 21. Practical Strategies for Psychological Measurement
---

## Learning Objectives {#Learning-Objectives-462pt} 

<i-callout variant="info" title="Learning Objectives">

1\. Specify the four broad steps in the measurement process.

2\. Explain how you would decide whether to use an existing measure or create your own.

3\. Describe multiple strategies to identify and locate existing measures of psychological constructs.

4\. Describe several general principles for creating new measures and for implementing existing and new measures.

5\. Create a simple plan for assessing the reliability and validity of an existing or new measure.

</i-callout>

So far in this chapter, we have considered several basic ideas about the nature of psychological constructs and their measurement. But now imagine that you are in the position of actually having to measure a psychological construct for a research project. How should you proceed? Broadly speaking, there are four steps in the measurement process: (a) conceptually defining the construct, (b) operationally defining the construct, (c) implementing the measure, and (d) evaluating the measure. In this section, we will look at each of these steps in turn.

## Conceptually Defining the Construct {#Conceptually-Defining-the-Construct-1681t} 

Having a clear and complete conceptual definition of a construct is a prerequisite for good measurement. For one thing, it allows you to make sound decisions about exactly how to measure the construct. If you had only a vague idea that you wanted to measure people’s “memory,” for example, you would have no way to choose whether you should have them remember a list of vocabulary words, a set of photographs, a newly learned skill, an experience from long ago, or have them remember to perform a task at a later time. Because psychologists now conceptualize memory as a set of semi-independent systems, you would have to be more precise about what you mean by “memory.” If you are interested in long-term episodic memory (memory for previous experiences), then having participants remember a list of words that they learned last week would make sense, but having them try to remember to execute a task in the future would not. In general, there is no substitute for reading the research literature on a construct and paying close attention to how others have defined it.

## Operationally Defining the Construct {#Operationally-Defining-the-Construct-1682t} 

Once you have a conceptual definition of the construct you are interested in studying it is time to operationally define the construct. Recall an operational definition is a definition of the variable in terms of precisely how it is to be measured. Since most variables are relatively abstract concepts that cannot be directly observed (e.g., stress), and observation is at the heart of the scientific method, conceptual definitions must be transformed into something that can be directly observed and measured. Most variables can be operationally defined in many different ways. For example, stress can be operationally defined as people’s scores on a stress scale such as the Perceived Stress Scale (Cohen, Kamarck, & Mermelstein, 1983) \[1\], cortisol concentrations in their saliva, or the number of stressful life events they have recently experienced. As described below, operationally defining your variable(s) of interest may involve using an existing measure or creating your own measure. 

### Using an Existing Measure {#using-an-existing-measure}

It is usually a good idea to use an existing measure that has been used successfully in previous research. Among the advantages are that (a) you save the time and trouble of creating your own, (b) there is already some evidence that the measure is valid (if it has been used successfully), and (c) your results can more easily be compared with and combined with previous results. In fact, if there already exists a reliable and valid measure of a construct, other researchers might expect you to use it unless you have a good and clearly stated reason for not doing so.

If you choose to use an existing measure, you may still have to choose among several alternatives. You might choose the most common one, the one with the best evidence of reliability and validity, the one that best measures a particular aspect of a construct that you are interested in (e.g., a physiological measure of stress if you are most interested in its underlying physiology), or even the one that would be easiest to use. For example, the Ten-Item Personality Inventory (TIPI) is a self-report questionnaire that measures all the Big Five personality dimensions with just 10 items (Gosling, Rentfrow, & Swann, 2003)\[2\]. It is not as reliable or valid as longer and more comprehensive measures, but a researcher might choose to use it when testing time is severely limited.

When an existing measure was created primarily for use in scientific research, it is usually described in detail in a published research article and is free to use in your own research—with a proper citation. You might find that later researchers who use the same measure describe it only briefly but provide a reference to the original article, in which case you would have to get the details from the original article. The American Psychological Association also publishes the _Directory of Unpublished Experimental Measures_ and _PsycTESTS_, which are extensive catalogs/collections of measures that have been used in previous research. Many existing measures—especially those that have applications in clinical psychology—are proprietary. This means that a publisher owns the rights to them and that you would have to purchase them. These include many standard intelligence tests, the Beck Depression Inventory, and the Minnesota Multiphasic Personality Inventory (MMPI). Details about many of these measures and how to obtain them can be found in other reference books, including _Tests in Print_ and the _Mental Measurements Yearbook_. There is a good chance you can find these reference books in your university library.

## Operationally Defining the Construct 2 {#Operationally-Defining-the-Construct-2-1683t .sr-only} 

### Creating Your Own Measure  {#creating-your-own-measure}

Instead of using an existing measure, you might want to create your own. Perhaps there is no existing measure of the construct you are interested in or existing ones are too difficult or time-consuming to use. Or perhaps you want to use a new measure specifically to see whether it works in the same way as existing measures—that is, to evaluate convergent validity. In this section, we consider some general issues in creating new measures that apply equally to self-report, behavioral, and physiological measures. More detailed guidelines for creating self-report measures are presented in Chapter 7.

First, be aware that most new measures in psychology are really variations of existing measures, so you should still look to the research literature for ideas. Perhaps you can modify an existing questionnaire, create a paper-and-pencil version of a measure that is normally computerized (or vice versa), or adapt a measure that has traditionally been used for another purpose. For example, the famous Stroop task (Stroop, 1935)\[3\]—in which people quickly name the colors that various color words are printed in—has been adapted for the study of social anxiety. People high in social anxiety are slower at color naming when the words have negative social connotations such as “stupid” (Amir, Freshman, & Foa, 2002)\[4\].

When you create a new measure, you should strive for simplicity. Remember that your participants are not as interested in your research as you are and that they will vary widely in their ability to understand and carry out whatever task you give them. You should create a set of clear instructions using simple language that you can present in writing or read aloud (or both). It is also a good idea to include one or more practice items so that participants can become familiar with the task, and to build in an opportunity for them to ask questions before continuing. It is also best to keep the measure brief to avoid boring or frustrating your participants to the point that their responses start to become less reliable and valid.

The need for brevity, however, needs to be weighed against the fact that it is nearly always better for a measure to include multiple items rather than a single item. There are two reasons for this. One is a matter of content validity. Multiple items are often required to cover a construct adequately. The other is a matter of reliability. People’s responses to single items can be influenced by all sorts of irrelevant factors—misunderstanding the particular item, a momentary distraction, or a simple error such as checking the wrong response option. But when several responses are summed or averaged, the effects of these irrelevant factors tend to cancel each other out to produce more reliable scores. Remember, however, that multiple items must be structured in a way that allows them to be combined into a single overall score by summing or averaging. To measure “financial responsibility,” a student might ask people about their annual income, obtain their credit score, and have them rate how “thrifty” they are—but there is no obvious way to combine these responses into an overall score. To create a true multiple-item measure, the student might instead ask people to rate the degree to which 10 statements about financial responsibility describe them on the same five-point scale.

Finally, the very best way to assure yourself that your measure has clear instructions, includes sufficient practice, and is an appropriate length is to test several people. Observe them as they complete the task, time them, and ask them afterward to comment on how easy or difficult it was, whether the instructions were clear, and anything else you might be wondering about. Obviously, it is better to discover problems with a measure before beginning any large-scale data collection.

## Implementing the Measure {#Implementing-the-Measure-1684t} 

You will want to implement any measure in a way that maximizes its reliability and validity. In most cases, it is best to test everyone under similar conditions that, ideally, are quiet and free of distractions. Participants are often tested in groups because it is efficient, but be aware that it can create distractions that reduce the reliability and validity of the measure. As always, it is good to use previous research as a guide. If others have successfully tested people in groups using a particular measure, then you should consider doing it too. 

Be aware also that people can react in a variety of ways to being measured that reduce the reliability and validity of the scores. Although some disagreeable participants might intentionally respond in ways meant to disrupt a study, participant reactivity is more likely to take the opposite form. Agreeable participants might respond in ways they believe they are expected to. Some participants might engage in **socially desirable responding**, doing or saying things because they think it is the socially appropriate thing. For example, people with low self-esteem agree that they feel they are a person of worth not because they really feel this way but because they believe this is the socially appropriate response and do not want to look bad in the eyes of the researcher. Additionally, research studies can have built-in **demand characteristics**: subtle cues that reveal how the researcher expects participants to behave. For example, a participant whose attitude toward exercise is measured immediately after she is asked to read a passage about the dangers of heart disease might reasonably conclude that the passage was meant to improve her attitude. As a result, she might respond more favorably because she believes she is expected to by the researcher. Finally, your own expectations can bias participants’ behaviors in unintended ways.

There are several precautions you can take to minimize these kinds of reactivity. One is to make the procedure as clear and brief as possible so that participants are not tempted to vent their frustrations on your results. Another is to guarantee participants’ anonymity and make clear to them that you are doing so. If you are testing them in groups, be sure that they are seated far enough apart that they cannot see each other’s responses. Give them all the same type of writing implement so that they cannot be identified by, for example, the pink glitter pen that they used. You can even allow them to seal completed questionnaires into individual envelopes or put them into a drop box where they immediately become mixed with others’ questionnaires. Although informed consent requires telling participants what they will be doing, it does not require revealing your hypothesis or other information that might suggest to participants how you expect them to respond. A questionnaire designed to measure financial responsibility need not be titled “Are You Financially Responsible?” It could be titled “Money Questionnaire” or have no title at all. Finally, the effects of your expectations can be minimized by arranging to have the measure administered by a helper who is “blind” or unaware of its intent or of any hypothesis being tested. Regardless of whether this is possible, you should standardize all interactions between researchers and participants—for example, by always reading the same set of instructions word for word.

## Evaluating the Measure {#Evaluating-the-Measure-1680t} 

Researchers should investigate potential issues with the measure, administration, conceptual definition, or experimental manipulation to determine the cause of the doubt.

## References {#References-463pt} 

1.  Cohen, S., Kamarck, T., & Mermelstein, R. (1983). A global measure of perceived stress. _Journal of Health and Social Behavior, 24_, 386-396.
2.  Gosling, S. D., Rentfrow, P. J., & Swann, W. B., Jr. (2003). A very brief measure of the Big Five personality domains. _Journal of Research in Personality, 37_, 504–528.
3.  Stroop, J. R. (1935). Studies of interference in serial verbal reactions. _Journal of Experimental Psychology, 18_, 643–662.
4.  Amir, N., Freshman, M., & Foa, E. (2002). Enhanced Stroop interference for threat in social phobia. _Journal of Anxiety Disorders, 16_, 1–9.

